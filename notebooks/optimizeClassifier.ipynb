{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.13/02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'postprocessing_utils' from '/home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/python/postprocessing_utils.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#import sys; sys.path.append(\"~/HHbbgg_ETH_devel/Training/python\") # to load packages\n",
    "import sys; sys.path.append(\"/home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/python\") # to load packages\n",
    "import training_utils as utils\n",
    "import numpy as np\n",
    "reload(utils)\n",
    "import preprocessing_utils as preprocessing\n",
    "reload(preprocessing)\n",
    "import plotting_utils as plotting\n",
    "reload(plotting)\n",
    "import optimization_utils as optimization\n",
    "reload(optimization)\n",
    "import postprocessing_utils as postprocessing\n",
    "reload(postprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: data=/home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2016\n",
      "env: data=/home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2017\n",
      "using background file n.0: /home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2016/DoubleEG_2016.root\n",
      "using background file n.1: /home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2017/DoubleEG_2017.root\n",
      "using signal file n.0: /home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2016/output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph_2016.root\n",
      "using signal file n.1: /home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2017/output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph_2017.root\n"
     ]
    }
   ],
   "source": [
    "ntuples = '2016'\n",
    "# \"%\" sign allows to interpret the rest as a system command\n",
    "%env data=$utils.IO.ldata$ntuples\n",
    "files = ! ls $data | sort -t_ -k 3 -n\n",
    "#signal = [s for s in files if \"output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph_2016_ptmjj.root\" in s]\n",
    "#bkgr = [s for s in files if \"DoubleEG_2016_ptmjj.root\" in s]\n",
    "signal = [s for s in files if \"output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph_2016.root\" in s]\n",
    "bkgr = [s for s in files if \"DoubleEG_2016.root\" in s]\n",
    "\n",
    "utils.IO.add_signal(ntuples,signal,1)\n",
    "utils.IO.add_background(ntuples,bkgr,-1)\n",
    "\n",
    "ntuples = '2017'\n",
    "# \"%\" sign allows to interpret the rest as a system command\n",
    "%env data=$utils.IO.ldata$ntuples\n",
    "files = ! ls $data | sort -t_ -k 3 -n\n",
    "#signal = [s for s in files if \"output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph_2017_ptmjj.root\" in s]\n",
    "#bkgr = [s for s in files if \"DoubleEG_2017_ptmjj.root\" in s]\n",
    "signal = [s for s in files if \"output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph_2017.root\" in s]\n",
    "bkgr = [s for s in files if \"DoubleEG_2017.root\" in s]\n",
    "utils.IO.add_signal(ntuples,signal,-1)\n",
    "utils.IO.add_background(ntuples,bkgr,-1)\n",
    "\n",
    "\n",
    "for i in range(len(utils.IO.backgroundName)):        \n",
    "    print \"using background file n.\"+str(i)+\": \"+utils.IO.backgroundName[i]\n",
    "for i in range(len(utils.IO.signalName)):    \n",
    "    print \"using signal file n.\"+str(i)+\": \"+utils.IO.signalName[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absCosThetaStar_CS', 'absCosTheta_bb', 'absCosTheta_gg', 'PhoJetMinDr', 'leadingJet_DeepCSV', 'subleadingJet_DeepCSV', 'leadingPhotonSigOverE', 'subleadingPhotonSigOverE', 'sigmaMOverM', 'diphotonCandidatePtOverdiHiggsM', 'dijetCandidatePtOverdiHiggsM', 'noexpand:leadingJet_bRegNNResolution/leadingJet_pt', 'noexpand:subleadingJet_bRegNNResolution/subleadingJet_pt', 'noexpand:sigmaMJets/Mjj', 'rho']\n",
      "['Data_13TeV_DoubleHTag_0']\n",
      "['Data_13TeV_DoubleHTag_0']\n",
      "using tree:GluGluToHHTo2B2G_node_SM_13TeV_madgraph_13TeV_DoubleHTag_0\n",
      "(508299, 15)\n",
      "(508299, 1)\n",
      "(508299, 15)\n",
      "(508299, 1)\n"
     ]
    }
   ],
   "source": [
    "#use noexpand for root expressions, it needs this file https://github.com/ibab/root_pandas/blob/master/root_pandas/readwrite.py\n",
    "#standart of input values \n",
    "branch_names = 'absCosThetaStar_CS,absCosTheta_bb,absCosTheta_gg,PhoJetMinDr,leadingJet_DeepCSV,subleadingJet_DeepCSV,leadingPhotonSigOverE,subleadingPhotonSigOverE,sigmaMOverM,diphotonCandidatePtOverdiHiggsM,dijetCandidatePtOverdiHiggsM,noexpand:leadingJet_bRegNNResolution/leadingJet_pt,noexpand:subleadingJet_bRegNNResolution/subleadingJet_pt,noexpand:sigmaMJets/Mjj,rho'.split(\",\")\n",
    "#st values with adding pt_gg/m_gg\n",
    "#branch_names = 'absCosThetaStar_CS,absCosTheta_bb,absCosTheta_gg,PhoJetMinDr,leadingJet_DeepCSV,subleadingJet_DeepCSV,leadingPhotonSigOverE,subleadingPhotonSigOverE,sigmaMOverM,diphotonCandidatePtOverdiHiggsM,dijetCandidatePtOverdiHiggsM,noexpand:leadingJet_bRegNNResolution/leadingJet_pt,noexpand:subleadingJet_bRegNNResolution/subleadingJet_pt,noexpand:sigmaMJets/Mjj,rho,noexpand:leadingPhoton_pt/CMS_hgg_mass,noexpand:subleadingPhoton_pt/CMS_hgg_mass'.split(\",\")\n",
    "#st values with adding pt_gg/m_gg, pt_jj/M_jj\n",
    "#branch_names = 'absCosThetaStar_CS,absCosTheta_bb,absCosTheta_gg,PhoJetMinDr,leadingJet_DeepCSV,subleadingJet_DeepCSV,leadingPhotonSigOverE,subleadingPhotonSigOverE,sigmaMOverM,diphotonCandidatePtOverdiHiggsM,dijetCandidatePtOverdiHiggsM,noexpand:leadingJet_bRegNNResolution/leadingJet_pt,noexpand:subleadingJet_bRegNNResolution/subleadingJet_pt,noexpand:sigmaMJets/Mjj,rho,noexpand:leadingPhoton_pt/CMS_hgg_mass,noexpand:subleadingPhoton_pt/CMS_hgg_mass,noexpand:leadingJet_pt/Mjj,noexpand:subleadingJet_pt/Mjj,PhoJetotherDr'.split(\",\")\n",
    "\n",
    "branch_names = [c.strip() for c in branch_names]\n",
    "#branch_names = (b.replace(\" \", \"_\") for b in branch_names)\n",
    "#branch_names = list(b.replace(\"-\", \"_\") for b in branch_names)\n",
    "print branch_names\n",
    "\n",
    "import pandas as pd\n",
    "import root_pandas as rpd\n",
    "from root_numpy import root2array, list_trees\n",
    "\n",
    "#print list_trees('/home/ovtin/cernbox/HHggbb/HHbbgg_ETH_devel/Training/2016/output_GluGluToHHTo2B2G_node_SM_13TeV-madgraph.root')\n",
    "for i in range(len(utils.IO.backgroundName)):        \n",
    "    print list_trees(utils.IO.backgroundName[i])\n",
    "        \n",
    "preprocessing.set_signals(\"GluGluToHHTo2B2G_node_SM_13TeV_madgraph_13TeV_DoubleHTag_0\",branch_names,True)\n",
    "preprocessing.set_backgrounds(\"Data_13TeV_DoubleHTag_0\",branch_names,True) \n",
    "X_bkg,y_bkg,weights_bkg,X_sig,y_sig,weights_sig=preprocessing.set_variables(branch_names)\n",
    "\n",
    "#relative weighting between components of one class is kept, all classes normalized to the same\n",
    "#weights_sig=preprocessing.weight_signal_with_resolution(weights_sig,y_sig)\n",
    "weights_bkg,weights_sig=preprocessing.normalize_process_weights(weights_bkg,y_bkg,weights_sig,y_sig)\n",
    "\n",
    "X_bkg,y_bkg,weights_bkg = preprocessing.randomize(X_bkg,y_bkg,weights_bkg)\n",
    "X_sig,y_sig,weights_sig = preprocessing.randomize(X_sig,y_sig,weights_sig)\n",
    "\n",
    "print X_bkg.shape\n",
    "print y_bkg.shape\n",
    "#bbggTrees have by default signal and CR events, let's be sure that we clean it\n",
    "X_bkg,y_bkg,weights_bkg,X_sig,y_sig,weights_sig=preprocessing.clean_signal_events(X_bkg,y_bkg,weights_bkg,X_sig,y_sig,weights_sig)\n",
    "print X_bkg.shape\n",
    "print y_bkg.shape\n",
    "\n",
    "y_total_train = preprocessing.get_total_training_sample(y_sig,y_bkg).ravel()\n",
    "X_total_train = preprocessing.get_total_training_sample(X_sig,X_bkg)\n",
    "\n",
    "y_total_test = preprocessing.get_total_test_sample(y_sig,y_bkg).ravel()\n",
    "X_total_test = preprocessing.get_total_test_sample(X_sig,X_bkg)\n",
    "\n",
    "w_total_train = preprocessing.get_total_training_sample(weights_sig,weights_bkg).ravel()\n",
    "w_total_test = preprocessing.get_total_test_sample(weights_sig,weights_bkg).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(max_depth=5,learning_rate=0.1,n_estimators=50, min_child_weight=1e-5, nthread= 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Optimization with randomized search cv=====\n",
      "-Initial Accuracy-\n",
      "Accuracy: 0.91768 (+/- 0.08310)\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ovtin/.local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   6 out of  12 | elapsed:  1.1min remaining:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done  12 out of  12 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set found on development set:\n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=4, min_child_weight=1e-05, missing=None, n_estimators=80,\n",
      "       n_jobs=1, nthread=12, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\n",
      "Grid scores on a subset of the development set:\n",
      "\n",
      "                                   params  mean_train_score  std_train_score  \\\n",
      "0  {u'n_estimators': 60, u'max_depth': 3}          0.968552         0.001040   \n",
      "1  {u'n_estimators': 80, u'max_depth': 3}          0.973408         0.000703   \n",
      "2  {u'n_estimators': 60, u'max_depth': 4}          0.975212         0.000656   \n",
      "3  {u'n_estimators': 80, u'max_depth': 4}          0.978777         0.000593   \n",
      "\n",
      "   mean_test_score  std_test_score  \n",
      "0         0.965645        0.002389  \n",
      "1         0.970031        0.001948  \n",
      "2         0.970231        0.002608  \n",
      "3         0.972818        0.001923  \n",
      "the best_params :  {'n_estimators': 80, 'max_depth': 4}\n",
      "the best_score  :  0.9728184266517358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ovtin/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ovtin/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ovtin/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ovtin/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ovtin/.local/lib/python2.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([24.85299476, 47.06372301, 50.12661497, 56.74168833]),\n",
       " 'mean_score_time': array([0.56259863, 0.97124664, 0.55741302, 0.74316295]),\n",
       " 'mean_test_score': array([0.96564518, 0.97003108, 0.9702306 , 0.97281843]),\n",
       " 'mean_train_score': array([0.96855181, 0.973408  , 0.97521188, 0.97877654]),\n",
       " 'param_max_depth': masked_array(data=[3, 3, 4, 4],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[60, 80, 60, 80],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 3, 'n_estimators': 60},\n",
       "  {'max_depth': 3, 'n_estimators': 80},\n",
       "  {'max_depth': 4, 'n_estimators': 60},\n",
       "  {'max_depth': 4, 'n_estimators': 80}],\n",
       " 'rank_test_score': array([4, 3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.96885498, 0.97246466, 0.9736189 , 0.97528787]),\n",
       " 'split0_train_score': array([0.96721649, 0.97260095, 0.97435845, 0.97811938]),\n",
       " 'split1_test_score': array([0.96312608, 0.96769615, 0.96727596, 0.97059737]),\n",
       " 'split1_train_score': array([0.96975433, 0.97431377, 0.9759549 , 0.97955651]),\n",
       " 'split2_test_score': array([0.96495448, 0.96993242, 0.96979693, 0.97257003]),\n",
       " 'split2_train_score': array([0.9686846 , 0.97330928, 0.97532227, 0.97865372]),\n",
       " 'std_fit_time': array([3.48812466, 3.18906359, 0.54888132, 2.79231131]),\n",
       " 'std_score_time': array([0.56635659, 0.34429053, 0.09511774, 0.35543536]),\n",
       " 'std_test_score': array([0.00238927, 0.00194799, 0.0026076 , 0.00192293]),\n",
       " 'std_train_score': array([0.00104032, 0.00070273, 0.00065641, 0.0005931 ])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils)\n",
    "import preprocessing_utils as preprocessing\n",
    "reload(preprocessing)\n",
    "import plotting_utils as plotting\n",
    "reload(plotting)\n",
    "import optimization_utils as optimization\n",
    "reload(optimization)\n",
    "import postprocessing_utils as postprocessing\n",
    "reload(postprocessing)\n",
    "import pandas as pd\n",
    "#param_grid = {\"n_estimators\": [1000,1500],\n",
    "#              \"max_depth\": [3,4,5],                                                                                                                                                                                                \n",
    "#              'reg_lambda':[0.1, 1]\n",
    "#              }\n",
    "#param_grid = {\"n_estimators\": [60,80],\n",
    "#              \"max_depth\": [3,4]                                                                                                                                                                                                \n",
    "#              }\n",
    "param_grid = {\"n_estimators\": [700,1500,2000],\n",
    "              \"max_depth\": [3, 4, 5, 8],                                                                                                                                            \n",
    "              'learning_rate': [0.01, 0.1],\n",
    "             } \n",
    "#optimization.optimize_parameters_randomizedCV(clf,X_total_train,y_total_train,param_grid,cvOpt=5,nIter=500,weights=w_total_train)\n",
    "#optimization.optimize_parameters_randomizedCV(clf,X_total_train,y_total_train,param_grid,cvOpt=3,weights=w_total_train)\n",
    "optimization.optimize_parameters_randomizedCV(clf,X_total_train,y_total_train,param_grid,cvOpt=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
